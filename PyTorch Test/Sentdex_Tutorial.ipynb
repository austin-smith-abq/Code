{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\austi\\miniconda3\\envs\\pydml\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:02, 4506112.24it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 29613421.68it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 5551742.60it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 43122161.61it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\austi\\miniconda3\\envs\\pydml\\lib\\site-packages\\torchvision\\datasets\\mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  D:\\a\\_work\\1\\s\\pytorch-directml\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform=transforms.Compose([transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 4, 9, 1, 1, 8, 7, 8, 0, 3])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[0][0].to('dml'), data[1][0].to('dml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28, 28))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "counter_dict = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f'{i}: {counter_dict[i]/total*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4155, -2.2911, -2.2318, -2.2373, -2.3612, -2.4134, -2.3163, -2.2428,\n",
       "         -2.4142, -2.1424]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pydml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9babaf5b982c7cccda308f903937e58a36c75ae706498de1212c1b30ab1e8a91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
